# Двоичное дерево поиска

Бинарное дерево поиска (англ. binary search tree, `BST`) &mdash; структура данных для работы с упорядоченными множествами.

> `BST` &mdash; это всего-лишь большой класс структур данных, которые основаны на одной идеи, поддерживать некоторое бинарное дерево. 

<p align="center">
  <img src="./bst.png" />
</p>

Название состоит из двух важных частей &mdash; `бинарное дерево` и `поиск`. Первое указывает на вид структуры данных, а второе на возможность удобного поиска в ней.

```admonish success title="Напоминание"
[Дерево](https://ru.wikipedia.org/wiki/%D0%94%D0%B5%D1%80%D0%B5%D0%B2%D0%BE_(%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%B3%D1%80%D0%B0%D1%84%D0%BE%D0%B2)) &mdash; это связный ациклический граф. 

Бинарное дерево &mdash; дерево в котором, у каждой вершины не более двух детей.
```

Представим, что числа из множества являются вершинами (как на картинке). Деревьев для нашего множества $\{1, 3, 4, 6, 7, 8, 10, 13, 14\}$ можно построить много :

TODO

Все `bst` удовлетворяют такому свойству : для каждого узла бинарного дерева с ключом $k$, все узлы в левом поддереве должны иметь ключи, меньшие $k$, а в правом поддереве большие $k$. Из определение следует, что дерево задаёт множество, то есть не хранит одинаковые числа по одному разу.

## Представление в памяти

1. Чаще всего дерево представляют в памяти как динамически создаваемая структура с явными указателями на своих детей. Вершина при создании не имеет детей, поэтому в конструкторе `Node` поля `l` и `r` мы инициализируем пустыми ссылками.

```cpp
struct Node {
    Node *l, *r;
    int x;
    Node(int x) : x(x), l(nullptr), r(nullptr) {};
};
```

2. Все узлы дерева хранятся в массиве. Поля детей имеют тип `int` и явно указывают позицию в массиве, где хранится в памяти узел ребёнка. Надо дополнительно написать конструктор по умолчанию, чтобы компилятор понял, какими объектами заполнить массив.

Вам может показаться, что этот способ не удобный, но скоро вы всё поймёте =)

```cpp
struct Node {
    int l, r;
    int x;
    Node(int x) : x(x), l(-1), r(-1) {};
    Node() : x(0), l(-1), r(-1) {};
    // или Node() = default;
};

Node mem[100000];
// code
assert(mem[239].l != -1);
cout << mem[mem[239].l].x;
```

Чтобы создать новый узел, стоит вернуть переменную, которая указывает на только-что созданный элемент. Просто замените `new Node(x)` на `new_Node(x)`.

```cpp
int pos = 0;

int new_Node(const T &x) {
  mem[pos] = T(x);
  return pos++;
}
```

Теперь все проверки вида `!= null` нужно заменить на `!= -1`. * Вообще можно хранить $0$ и все проверки писать, как `if (v) { ...}`.

~~~admonish title="Способ 1 с глобальным массивом"

Чтобы создать новый узел, стоит вернуть память под `pos`, и подвинуть `pos`.

```cpp
struct Node {
    Node *l, *r;
    int x;
    Node(int x) : x(x), l(nullptr), r(nullptr) {};
    Node() = default;
};
Node mem[100000];
int pos = 0;

Node* new_Node(const T &x) {
  mem[pos] = T(x);
  return &mem[pos++];
}
```
~~~

```admonish warning title="Микро оптимизация"
Второй способ является более оптимальным. Так как память выделяется сразу большим куском, а не на каждый вызов `new`. Хотя это выглядит логичной оптимизацией, которая ускорит программу значительно, но это не совсем так. Можно прочитать обсуждения, например [тут](https://www.quora.com/How-much-faster-is-static-memory-allocation-compared-to-dynamic-memory-allocation-in-C).

Грубо говоря пример 1 с массивом даст прирост производительности по времени в $3-5\%$. Но тут вступает в дело размер указателей на детей. На самом деле указатель на современных машинах занимает $8$ байт, а `int` всего $4$.

Предлагаю подумать на эту тему =)

Поэтому рекомендуется использовать второй способ для всех динамически создаваемых структур=)

TODO мне чёт в лом, AVL переписывать =)
```

## Поиск

Преимущество бинарных деревьев поиска в том, что в них можно легко производить поиск элементов. Если поиск удобный, то и другие операции просты и выражаются через поиск.

```cpp
bool find(Node *v, int x) {
    if (!v)
        return false;
    if (v->x == x)
        return true;
    if (v->x < x) {
      return find(v->l, x);
    } else {
      return find(v->r, x);
    }
}
```

## Удаление

## Добавление

## Минимум/Максимум

### Поиск следующего и предыдущего элемента

## Обходы

## Асимптотика

Все операции над деревом такие, как вставка, удаление, поиск элементов &mdash; работают в среднем $O(\log n)$. В худшем случае за $O(n)$

```admonish tile="Доказательство"

Предложение : дерево из $n$ ключей имеет в среднем $\approx 2 \ln n$.

Доказательство : 

<!--
https://stackoverflow.com/questions/61428477/how-to-prove-average-height-of-binary-search-tree-is-ologn
https://cs.stackexchange.com/questions/54071/prove-that-the-depth-function-of-a-binary-search-tree-is-o-log-n-on-average
https://math.stackexchange.com/questions/3224473/how-come-the-time-complexity-of-binary-search-is-log-n
 -->

TODO
```

В худшем случае за высоту дерева. Это означает, что дерево без некоторой "ребалансировки" после некоторых вставок или удалений, может иметь высоту $n$, где $n$ количество вершин в дереве.

Дерево с наибольшей высотой &mdash; бамбук.

TODO бамбук нарисовать, и запросы как оно стоится

Сохранение сбалансированности дерева поиска и его высоты, ограниченной $O(\log n)$, является ключевым условием полезности бинарного дерева поиска. Этого можно достичь с помощью механизмов "самобалансировки" при операциях обновления дерева, призванных поддерживать высоту дерева на уровне $\log n$. 

Деревья могут иметь разные механизмы самобалансировки, такие как :
1. Сбалансированные по высоте
2. [Сбалансированные по весу деревья](https://en.wikipedia.org/wiki/Weight-balanced_tree) &mdashl; не будем рассматривать в виду того, что на википедии приведён пример, но название структуре данных не дано. Если вы любите `Haskell` то изучите.

Существует несколько самобалансирующихся по высоте бинарных деревьев поиска : AVL, декартово, красно чёрное, $2-3$, Splay.